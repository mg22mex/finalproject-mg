"use strict";
var __webpack_require__ = {};
(()=>{
    __webpack_require__.d = (exports1, definition)=>{
        for(var key in definition)if (__webpack_require__.o(definition, key) && !__webpack_require__.o(exports1, key)) Object.defineProperty(exports1, key, {
            enumerable: true,
            get: definition[key]
        });
    };
})();
(()=>{
    __webpack_require__.o = (obj, prop)=>Object.prototype.hasOwnProperty.call(obj, prop);
})();
(()=>{
    __webpack_require__.r = (exports1)=>{
        if ('undefined' != typeof Symbol && Symbol.toStringTag) Object.defineProperty(exports1, Symbol.toStringTag, {
            value: 'Module'
        });
        Object.defineProperty(exports1, '__esModule', {
            value: true
        });
    };
})();
var __webpack_exports__ = {};
__webpack_require__.r(__webpack_exports__);
__webpack_require__.d(__webpack_exports__, {
    plan: ()=>plan
});
const env_namespaceObject = require("@midscene/shared/env");
const img_namespaceObject = require("@midscene/shared/img");
const logger_namespaceObject = require("@midscene/shared/logger");
const utils_namespaceObject = require("@midscene/shared/utils");
const external_common_js_namespaceObject = require("./common.js");
const llm_planning_js_namespaceObject = require("./prompt/llm-planning.js");
const util_js_namespaceObject = require("./prompt/util.js");
const debug = (0, logger_namespaceObject.getDebug)('planning');
async function plan(userInstruction, opts) {
    var _planFromAI_action;
    const { callAI, context } = opts || {};
    const { screenshotBase64, size } = context;
    const modelPreferences = {
        intent: 'planning'
    };
    const { description: pageDescription, elementById } = await (0, util_js_namespaceObject.describeUserPage)(context, modelPreferences);
    const systemPrompt = await (0, llm_planning_js_namespaceObject.systemPromptToTaskPlanning)({
        actionSpace: opts.actionSpace,
        vlMode: (0, env_namespaceObject.vlLocateMode)(modelPreferences)
    });
    const taskBackgroundContextText = (0, llm_planning_js_namespaceObject.generateTaskBackgroundContext)(userInstruction, opts.log, opts.actionContext);
    const userInstructionPrompt = await (0, llm_planning_js_namespaceObject.automationUserPrompt)((0, env_namespaceObject.vlLocateMode)(modelPreferences)).format({
        pageDescription,
        taskBackgroundContext: taskBackgroundContextText
    });
    let imagePayload = screenshotBase64;
    if ('qwen-vl' === (0, env_namespaceObject.vlLocateMode)(modelPreferences)) imagePayload = await (0, img_namespaceObject.paddingToMatchBlockByBase64)(imagePayload);
    else if (!(0, env_namespaceObject.vlLocateMode)(modelPreferences)) imagePayload = await (0, external_common_js_namespaceObject.markupImageForLLM)(screenshotBase64, context.tree, context.size);
    (0, external_common_js_namespaceObject.warnGPT4oSizeLimit)(size, modelPreferences);
    const msgs = [
        {
            role: 'system',
            content: systemPrompt
        },
        {
            role: 'user',
            content: [
                {
                    type: 'image_url',
                    image_url: {
                        url: imagePayload,
                        detail: 'high'
                    }
                },
                {
                    type: 'text',
                    text: userInstructionPrompt
                }
            ]
        }
    ];
    const call = callAI || external_common_js_namespaceObject.callAiFn;
    const { content, usage } = await call(msgs, external_common_js_namespaceObject.AIActionType.PLAN, modelPreferences);
    const rawResponse = JSON.stringify(content, void 0, 2);
    const planFromAI = content;
    const actions = ((null == (_planFromAI_action = planFromAI.action) ? void 0 : _planFromAI_action.type) ? [
        planFromAI.action
    ] : planFromAI.actions) || [];
    const returnValue = {
        ...planFromAI,
        actions,
        rawResponse,
        usage,
        yamlFlow: (0, external_common_js_namespaceObject.buildYamlFlowFromPlans)(actions, opts.actionSpace, planFromAI.sleep)
    };
    (0, utils_namespaceObject.assert)(planFromAI, "can't get plans from AI");
    actions.forEach((action)=>{
        const type = action.type;
        const actionInActionSpace = opts.actionSpace.find((action)=>action.name === type);
        const locateFields = actionInActionSpace ? (0, external_common_js_namespaceObject.findAllMidsceneLocatorField)(actionInActionSpace.paramSchema) : [];
        debug('locateFields', locateFields);
        locateFields.forEach((field)=>{
            const locateResult = action.param[field];
            if (locateResult) if ((0, env_namespaceObject.vlLocateMode)(modelPreferences)) action.param[field] = (0, external_common_js_namespaceObject.fillBboxParam)(locateResult, size.width, size.height, modelPreferences);
            else {
                const element = elementById(locateResult);
                if (element) action.param[field].id = element.id;
            }
        });
    });
    (0, utils_namespaceObject.assert)(!planFromAI.error, `Failed to plan actions: ${planFromAI.error}`);
    if (0 === actions.length && returnValue.more_actions_needed_by_instruction && !returnValue.sleep) console.warn('No actions planned for the prompt, but model said more actions are needed:', userInstruction);
    return returnValue;
}
exports.plan = __webpack_exports__.plan;
for(var __webpack_i__ in __webpack_exports__)if (-1 === [
    "plan"
].indexOf(__webpack_i__)) exports[__webpack_i__] = __webpack_exports__[__webpack_i__];
Object.defineProperty(exports, '__esModule', {
    value: true
});

//# sourceMappingURL=llm-planning.js.map